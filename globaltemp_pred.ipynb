{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/02 19:31:44 WARN Utils: Your hostname, MacBook-Pro-584.local resolves to a loopback address: 127.0.0.1; using 10.0.0.170 instead (on interface en0)\n",
      "25/03/02 19:31:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/02 19:31:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "ss = SparkSession.builder.getOrCreate()\n",
    "ss.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ClimateIndicators', 'admin', 'climate_db', 'config', 'local', 'mongodbVSCodePlaygroundDB', 'msds', 'msds697', 'test']\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient(\"mongodb+srv://climateindicators:climatemongo@usf.6ejgq.mongodb.net/\")\n",
    "print(client.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['climateindicators-dds_icesheet',\n",
       " 'climateindicators-dds_lpi',\n",
       " 'climateindicators-dds_co2',\n",
       " 'climateindicators-dds_globaltemp',\n",
       " 'climateindicators-dds_sealevel']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.climate_db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+---------+\n",
      "|year|No_Smoothing|Lowess(5)|\n",
      "+----+------------+---------+\n",
      "|1880|       -0.17|     -0.1|\n",
      "|1881|       -0.09|    -0.13|\n",
      "|1882|       -0.11|    -0.17|\n",
      "|1883|       -0.17|     -0.2|\n",
      "|1884|       -0.28|    -0.24|\n",
      "|1885|       -0.33|    -0.26|\n",
      "|1886|       -0.31|    -0.27|\n",
      "|1887|       -0.36|    -0.27|\n",
      "|1888|       -0.17|    -0.26|\n",
      "|1889|       -0.11|    -0.26|\n",
      "|1890|       -0.35|    -0.25|\n",
      "|1891|       -0.22|    -0.26|\n",
      "|1892|       -0.27|    -0.26|\n",
      "|1893|       -0.31|    -0.26|\n",
      "|1894|        -0.3|    -0.24|\n",
      "|1895|       -0.23|    -0.22|\n",
      "|1896|       -0.11|    -0.21|\n",
      "|1897|       -0.11|    -0.18|\n",
      "|1898|       -0.27|    -0.17|\n",
      "|1899|       -0.18|    -0.18|\n",
      "+----+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db = client[\"climate_db\"]\n",
    "collection = db[\"climateindicators-dds_globaltemp\"]\n",
    "data = list(collection.find({},  {\"_id\": 0}))\n",
    "df = ss.createDataFrame(pd.DataFrame(data))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+---------+---------------+---------------+---------------+---------------+---------------+\n",
      "|year|No_Smoothing|Lowess(5)|lag_1_no_smooth|lag_2_no_smooth|lag_3_no_smooth|lag_4_no_smooth|lag_5_no_smooth|\n",
      "+----+------------+---------+---------------+---------------+---------------+---------------+---------------+\n",
      "|1885|       -0.33|    -0.26|          -0.28|          -0.17|          -0.11|          -0.09|          -0.17|\n",
      "|1886|       -0.31|    -0.27|          -0.33|          -0.28|          -0.17|          -0.11|          -0.09|\n",
      "|1887|       -0.36|    -0.27|          -0.31|          -0.33|          -0.28|          -0.17|          -0.11|\n",
      "|1888|       -0.17|    -0.26|          -0.36|          -0.31|          -0.33|          -0.28|          -0.17|\n",
      "|1889|       -0.11|    -0.26|          -0.17|          -0.36|          -0.31|          -0.33|          -0.28|\n",
      "|1890|       -0.35|    -0.25|          -0.11|          -0.17|          -0.36|          -0.31|          -0.33|\n",
      "|1891|       -0.22|    -0.26|          -0.35|          -0.11|          -0.17|          -0.36|          -0.31|\n",
      "|1892|       -0.27|    -0.26|          -0.22|          -0.35|          -0.11|          -0.17|          -0.36|\n",
      "|1893|       -0.31|    -0.26|          -0.27|          -0.22|          -0.35|          -0.11|          -0.17|\n",
      "|1894|        -0.3|    -0.24|          -0.31|          -0.27|          -0.22|          -0.35|          -0.11|\n",
      "|1895|       -0.23|    -0.22|           -0.3|          -0.31|          -0.27|          -0.22|          -0.35|\n",
      "|1896|       -0.11|    -0.21|          -0.23|           -0.3|          -0.31|          -0.27|          -0.22|\n",
      "|1897|       -0.11|    -0.18|          -0.11|          -0.23|           -0.3|          -0.31|          -0.27|\n",
      "|1898|       -0.27|    -0.17|          -0.11|          -0.11|          -0.23|           -0.3|          -0.31|\n",
      "|1899|       -0.18|    -0.18|          -0.27|          -0.11|          -0.11|          -0.23|           -0.3|\n",
      "|1900|       -0.09|     -0.2|          -0.18|          -0.27|          -0.11|          -0.11|          -0.23|\n",
      "|1901|       -0.16|    -0.24|          -0.09|          -0.18|          -0.27|          -0.11|          -0.11|\n",
      "|1902|       -0.28|    -0.26|          -0.16|          -0.09|          -0.18|          -0.27|          -0.11|\n",
      "|1903|       -0.37|    -0.28|          -0.28|          -0.16|          -0.09|          -0.18|          -0.27|\n",
      "|1904|       -0.47|    -0.31|          -0.37|          -0.28|          -0.16|          -0.09|          -0.18|\n",
      "+----+------------+---------+---------------+---------------+---------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.orderBy(\"year\")\n",
    "\n",
    "df_lags = df.withColumn(\"lag_1_no_smooth\", lag(col(\"No_Smoothing\"), 1).over(window_spec))\n",
    "df_lags = df_lags.withColumn(\"lag_2_no_smooth\", lag(col(\"No_Smoothing\"), 2).over(window_spec))\n",
    "df_lags = df_lags.withColumn(\"lag_3_no_smooth\", lag(col(\"No_Smoothing\"), 3).over(window_spec))\n",
    "df_lags = df_lags.withColumn(\"lag_4_no_smooth\", lag(col(\"No_Smoothing\"), 4).over(window_spec))\n",
    "df_lags = df_lags.withColumn(\"lag_5_no_smooth\", lag(col(\"No_Smoothing\"), 5).over(window_spec))\n",
    "\n",
    "df_lags = df_lags.dropna()\n",
    "\n",
    "df_lags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----+\n",
      "|year|            features|label|\n",
      "+----+--------------------+-----+\n",
      "|1885|[-0.28,-0.17,-0.1...|-0.33|\n",
      "|1886|[-0.33,-0.28,-0.1...|-0.31|\n",
      "|1887|[-0.31,-0.33,-0.2...|-0.36|\n",
      "|1888|[-0.36,-0.31,-0.3...|-0.17|\n",
      "|1889|[-0.17,-0.36,-0.3...|-0.11|\n",
      "|1890|[-0.11,-0.17,-0.3...|-0.35|\n",
      "|1891|[-0.35,-0.11,-0.1...|-0.22|\n",
      "|1892|[-0.22,-0.35,-0.1...|-0.27|\n",
      "|1893|[-0.27,-0.22,-0.3...|-0.31|\n",
      "|1894|[-0.31,-0.27,-0.2...| -0.3|\n",
      "|1895|[-0.3,-0.31,-0.27...|-0.23|\n",
      "|1896|[-0.23,-0.3,-0.31...|-0.11|\n",
      "|1897|[-0.11,-0.23,-0.3...|-0.11|\n",
      "|1898|[-0.11,-0.11,-0.2...|-0.27|\n",
      "|1899|[-0.27,-0.11,-0.1...|-0.18|\n",
      "|1900|[-0.18,-0.27,-0.1...|-0.09|\n",
      "|1901|[-0.09,-0.18,-0.2...|-0.16|\n",
      "|1902|[-0.16,-0.09,-0.1...|-0.28|\n",
      "|1903|[-0.28,-0.16,-0.0...|-0.37|\n",
      "|1904|[-0.37,-0.28,-0.1...|-0.47|\n",
      "+----+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"lag_1_no_smooth\", \"lag_2_no_smooth\", \"lag_3_no_smooth\", \"lag_4_no_smooth\", \"lag_5_no_smooth\"]\n",
    "\n",
    "assembler_no_smooth = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "\n",
    "df_feat = assembler_no_smooth.transform(df_lags).select(\"year\", \"features\", col(\"No_Smoothing\").alias(\"label\"))\n",
    "\n",
    "df_feat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 111, test size: 29\n",
      "Split year: 1995.0\n"
     ]
    }
   ],
   "source": [
    "df_ordered = df_feat.orderBy(\"year\")\n",
    "split_year = df_ordered.approxQuantile(\"year\", [0.8], 0.01)[0]\n",
    "\n",
    "train = df_feat.filter(col(\"year\") <= split_year)\n",
    "test = df_feat.filter(col(\"year\") > split_year)\n",
    "\n",
    "print(f\"train size: {train.count()}, test size: {test.count()}\")\n",
    "print(f\"Split year: {split_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train years: 1885 to 1995\n",
      "Test years: 1996 to 2024\n"
     ]
    }
   ],
   "source": [
    "train_pd = train.select(\"year\", \"label\").toPandas()\n",
    "test_pd = test.select(\"year\", \"label\").toPandas()\n",
    "print(f\"Train years: {min(train_pd['year'])} to {max(train_pd['year'])}\")\n",
    "print(f\"Test years: {min(test_pd['year'])} to {max(test_pd['year'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/Users/anyxling/python-general/lib/python3.12/site-packages/pyspark/jars/spark-core_2.12-3.5.3.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------------+\n",
      "|year|label|         prediction|\n",
      "+----+-----+-------------------+\n",
      "|1996| 0.33|0.30772384199134206|\n",
      "|1997| 0.46| 0.3065821753246754|\n",
      "|1998| 0.61|0.30796443722943734|\n",
      "|1999| 0.38|0.30864884199134207|\n",
      "|2000| 0.39| 0.3062844372294374|\n",
      "|2001| 0.53| 0.3075469372294373|\n",
      "|2002| 0.63| 0.3075469372294373|\n",
      "|2003| 0.61| 0.3075469372294373|\n",
      "|2004| 0.53| 0.3075469372294373|\n",
      "|2005| 0.68| 0.3075469372294373|\n",
      "|2006| 0.63| 0.3075469372294373|\n",
      "|2007| 0.66| 0.3075469372294373|\n",
      "|2008| 0.54| 0.3075469372294373|\n",
      "|2009| 0.65| 0.3075469372294373|\n",
      "|2010| 0.72| 0.3075469372294373|\n",
      "|2011| 0.61| 0.3075469372294373|\n",
      "|2012| 0.64| 0.3075469372294373|\n",
      "|2013| 0.67| 0.3075469372294373|\n",
      "|2014| 0.75| 0.3075469372294373|\n",
      "|2015| 0.89| 0.3075469372294373|\n",
      "+----+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", \n",
    "                          labelCol=\"label\", \n",
    "                          numTrees=100,     # Reduced from 200\n",
    "                          maxDepth=5,       # Reduced from 10\n",
    "                          minInstancesPerNode=5, # Increased from 2\n",
    "                          maxBins=32)       # Added parameter\n",
    "model = rf.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "predictions.select(\"year\", \"label\", \"prediction\").orderBy(\"year\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.46999072962281657\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecast next 100 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 observed values: [1.01, 0.84, 0.89, 1.17, 1.28]\n",
      "Forecast for the next 100 years:\n",
      "Year +1: 0.9815144533244533\n",
      "Year +2: 0.9882835009435008\n",
      "Year +3: 0.984066477133977\n",
      "Year +4: 0.9833455247530247\n",
      "Year +5: 0.9833455247530247\n",
      "Year +6: 0.9833455247530247\n",
      "Year +7: 0.9833455247530247\n",
      "Year +8: 0.9833455247530247\n",
      "Year +9: 0.9833455247530247\n",
      "Year +10: 0.9833455247530247\n",
      "Year +11: 0.9833455247530247\n",
      "Year +12: 0.9833455247530247\n",
      "Year +13: 0.9833455247530247\n",
      "Year +14: 0.9833455247530247\n",
      "Year +15: 0.9833455247530247\n",
      "Year +16: 0.9833455247530247\n",
      "Year +17: 0.9833455247530247\n",
      "Year +18: 0.9833455247530247\n",
      "Year +19: 0.9833455247530247\n",
      "Year +20: 0.9833455247530247\n",
      "Year +21: 0.9833455247530247\n",
      "Year +22: 0.9833455247530247\n",
      "Year +23: 0.9833455247530247\n",
      "Year +24: 0.9833455247530247\n",
      "Year +25: 0.9833455247530247\n",
      "Year +26: 0.9833455247530247\n",
      "Year +27: 0.9833455247530247\n",
      "Year +28: 0.9833455247530247\n",
      "Year +29: 0.9833455247530247\n",
      "Year +30: 0.9833455247530247\n",
      "Year +31: 0.9833455247530247\n",
      "Year +32: 0.9833455247530247\n",
      "Year +33: 0.9833455247530247\n",
      "Year +34: 0.9833455247530247\n",
      "Year +35: 0.9833455247530247\n",
      "Year +36: 0.9833455247530247\n",
      "Year +37: 0.9833455247530247\n",
      "Year +38: 0.9833455247530247\n",
      "Year +39: 0.9833455247530247\n",
      "Year +40: 0.9833455247530247\n",
      "Year +41: 0.9833455247530247\n",
      "Year +42: 0.9833455247530247\n",
      "Year +43: 0.9833455247530247\n",
      "Year +44: 0.9833455247530247\n",
      "Year +45: 0.9833455247530247\n",
      "Year +46: 0.9833455247530247\n",
      "Year +47: 0.9833455247530247\n",
      "Year +48: 0.9833455247530247\n",
      "Year +49: 0.9833455247530247\n",
      "Year +50: 0.9833455247530247\n",
      "Year +51: 0.9833455247530247\n",
      "Year +52: 0.9833455247530247\n",
      "Year +53: 0.9833455247530247\n",
      "Year +54: 0.9833455247530247\n",
      "Year +55: 0.9833455247530247\n",
      "Year +56: 0.9833455247530247\n",
      "Year +57: 0.9833455247530247\n",
      "Year +58: 0.9833455247530247\n",
      "Year +59: 0.9833455247530247\n",
      "Year +60: 0.9833455247530247\n",
      "Year +61: 0.9833455247530247\n",
      "Year +62: 0.9833455247530247\n",
      "Year +63: 0.9833455247530247\n",
      "Year +64: 0.9833455247530247\n",
      "Year +65: 0.9833455247530247\n",
      "Year +66: 0.9833455247530247\n",
      "Year +67: 0.9833455247530247\n",
      "Year +68: 0.9833455247530247\n",
      "Year +69: 0.9833455247530247\n",
      "Year +70: 0.9833455247530247\n",
      "Year +71: 0.9833455247530247\n",
      "Year +72: 0.9833455247530247\n",
      "Year +73: 0.9833455247530247\n",
      "Year +74: 0.9833455247530247\n",
      "Year +75: 0.9833455247530247\n",
      "Year +76: 0.9833455247530247\n",
      "Year +77: 0.9833455247530247\n",
      "Year +78: 0.9833455247530247\n",
      "Year +79: 0.9833455247530247\n",
      "Year +80: 0.9833455247530247\n",
      "Year +81: 0.9833455247530247\n",
      "Year +82: 0.9833455247530247\n",
      "Year +83: 0.9833455247530247\n",
      "Year +84: 0.9833455247530247\n",
      "Year +85: 0.9833455247530247\n",
      "Year +86: 0.9833455247530247\n",
      "Year +87: 0.9833455247530247\n",
      "Year +88: 0.9833455247530247\n",
      "Year +89: 0.9833455247530247\n",
      "Year +90: 0.9833455247530247\n",
      "Year +91: 0.9833455247530247\n",
      "Year +92: 0.9833455247530247\n",
      "Year +93: 0.9833455247530247\n",
      "Year +94: 0.9833455247530247\n",
      "Year +95: 0.9833455247530247\n",
      "Year +96: 0.9833455247530247\n",
      "Year +97: 0.9833455247530247\n",
      "Year +98: 0.9833455247530247\n",
      "Year +99: 0.9833455247530247\n",
      "Year +100: 0.9833455247530247\n"
     ]
    }
   ],
   "source": [
    "# train model on all available data first\n",
    "model = rf.fit(df_feat)\n",
    "\n",
    "# extract the last 5 observations\n",
    "last5 = (\n",
    "    df_feat.orderBy(col(\"year\").desc())\n",
    "           .limit(5)\n",
    "           .orderBy(col(\"year\").asc())\n",
    "           .select(\"label\")\n",
    "           .rdd.flatMap(lambda x: x)\n",
    "           .collect()\n",
    ")\n",
    "\n",
    "print(\"Last 5 observed values:\", last5)\n",
    "\n",
    "# forecast the next 100 time steps (years)\n",
    "forecast_years = 100\n",
    "forecast = []\n",
    "current_lags = last5[:]  # make a copy of the last 5 values\n",
    "\n",
    "for i in range(forecast_years):\n",
    "    # DenseVector for current lag features\n",
    "    features_vector = Vectors.dense(current_lags)\n",
    "    \n",
    "    # create a single-row df for prediction\n",
    "    pred_df = ss.createDataFrame([(features_vector,)], [\"features\"])\n",
    "    \n",
    "    pred_value = model.transform(pred_df).select(\"prediction\").collect()[0][0]\n",
    "    forecast.append(pred_value)\n",
    "    \n",
    "    # update current_lags: drop the oldest lag and append the new prediction\n",
    "    current_lags = current_lags[1:] + [pred_value]\n",
    "\n",
    "print(\"Forecast for the next 100 years:\")\n",
    "for i, val in enumerate(forecast, 1):\n",
    "    print(f\"Year +{i}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series prediction in PySpark has limitations because it does not natively support models like ARIMA/SARIMA, LSTMs, or Prophet. Though achieving highly accurate forecasts may be challenging, this is a good practice to apply ML techniques in PySpark and explore feature engineering with lagged variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
